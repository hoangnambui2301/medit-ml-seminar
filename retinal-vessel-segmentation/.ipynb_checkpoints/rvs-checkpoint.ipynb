{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f361b8-9776-419d-bf1e-115c10593fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import losses\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Input, MaxPooling2D\n",
    "from keras.layers import concatenate, Conv2D, Conv2DTranspose, Dropout, ReLU\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1989f89-5a18-402c-ab3c-7905e6db45c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "input_shape = (64, 64)\n",
    "\n",
    "def custom_activation(x):\n",
    "    return K.relu(x, alpha=0.0, max_value=1)\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "smooth = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f80f8-c643-4b28-be27-6b6926b031c4",
   "metadata": {},
   "source": [
    "## U-Net architecture\n",
    "| ![](https://camo.githubusercontent.com/bc2e09476b5c7db5ea4e19251ac9a19af9ba5a89f16d58f72459059c3cffb969/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a6a716f416d4579516d784b704763416b6250474e4d512e706e67) |\n",
    "|:--:|\n",
    "| <b>U-Net model</b> |\n",
    "\n",
    "The U-Net is convolutional network architecture for fast and precise segmentation of images. It is an encoder-decoder model with some skip connections between. The major advantage of this architecture is its ability to take into account a wider context when making a prediction for a pixel (foreground vs. background). This model consists of large number of channels used in the up-sampling operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca21581-64bd-4d3c-9c1d-e5e7c98d135a",
   "metadata": {},
   "source": [
    "#### Input image processing\n",
    "There are several processing steps before feeding it into the U-Net.\n",
    "- Normalization: used to normalize the pixel intensities in the range of 0-1.\n",
    "- Cropping: used to adjust the suitable image size for the whole network.\n",
    "- Data augmentation: used to solve the problem of data insufficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2416b4d-6b98-4cd7-9be3-f0909f5181f6",
   "metadata": {},
   "source": [
    "### Define the U-Net model\n",
    "- Adjust the input image to the Convolution operation with the kernel of 3x3 and the padding of 0.\n",
    "- Apply the previous Convolution output to the Dropout operation.\n",
    "- Apply one more Dropout operation on the previous Dropout output.\n",
    "- Apply the Max Pooling operation on the last Dropout output with the pool size of 2x2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c18a274-bdda-40ba-9286-bde08a394215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(do=0, activation=ReLU):\n",
    "    inputs = Input((None, None, 3))\n",
    "    conv1 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(inputs)))\n",
    "    conv1 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(conv1)))\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(pool1)))\n",
    "    conv2 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(conv2)))\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(pool2)))\n",
    "    conv3 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(conv3)))\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(pool3)))\n",
    "    conv4 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(conv4)))\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Dropout(do)(activation()(Conv2D(512, (3, 3), padding='same')(pool4)))\n",
    "    conv5 = Dropout(do)(activation()(Conv2D(512, (3, 3), padding='same')(conv5)))\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(up6)))\n",
    "    conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(conv6)))\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(up7)))\n",
    "    conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(conv7)))\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(up8)))\n",
    "    conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(conv8)))\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(up9)))\n",
    "    conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(conv9)))\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss=losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855fdaf-399f-4ea8-b6f9-6374a5ff536c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
