{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc337c-ad48-4656-ade0-ea39bcead6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary libraries and tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee7674-be0e-4560-8fef-23bd0aafaa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a first look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9640a4e-4306-4734-b31f-cade4d96f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad602191-5865-46e8-955e-c308355c47a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e7cd4-e9e8-48e1-b9f7-39ccf94e943c",
   "metadata": {},
   "source": [
    "### Classification of data types\n",
    "Before going to any training, we should classify the types of data into two different kinds: 'categorical_val' for whose the unique data is less than 10 different values (e.g. age, sex...) and 'continuous_val' vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e3c59-8213-48a4-bd10-ed01bc97171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill your answer in '...'\n",
    "categorical_val = []\n",
    "continuous_val = []\n",
    "for col in ...:\n",
    "    if ...:\n",
    "        ...\n",
    "    else:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f5d6c-d880-4765-af44-7a8901fe3001",
   "metadata": {},
   "source": [
    "### Create dummies and scale data\n",
    "After exploring the dataset, we need to convert some categorical variables into dummy variables and scale all the values before training the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95baba-eca8-4118-b666-0f4444a2288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create dummies\n",
    "'''\n",
    "# Please fill your answer in '...'\n",
    "categorical_val.remove('target')\n",
    "dataset = pd.get_dummies(..., columns=...)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93852af5-7a50-42a7-b7ad-660d85925bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Scale the values\n",
    "- Set the array of columns to scale.\n",
    "'''\n",
    "# Please fill your answer in '...'\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "s_sc = StandardScaler()\n",
    "col_to_scale = ...\n",
    "dataset[col_to_scale] = s_sc.fit_transform(dataset[col_to_scale])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff3a50-f94a-4b05-8c34-4f697d4b5caf",
   "metadata": {},
   "source": [
    "#### Define function to print the accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df7885-7c9c-42b8-be00-f998d1f88743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, x_train, y_train, x_test, y_test, train):\n",
    "    if train == True:\n",
    "        pred = clf.predict(x_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(f'Accuracy Score: {accuracy_score(y_train, pred) * 100:.4f}%')\n",
    "        print('______________________________________________________________________')\n",
    "        print(f'Classification Report:\\n{clf_report}')\n",
    "#         print('______________________________________________________________________')\n",
    "#         print(f'Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n')\n",
    "    elif train == False:\n",
    "        pred = clf.predict(x_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(f'Accuracy Score: {accuracy_score(y_test, pred) * 100:.4f}%')\n",
    "        print('______________________________________________________________________')\n",
    "        print(f'Classification Report:\\n{clf_report}')\n",
    "#         print('______________________________________________________________________')\n",
    "#         print(f'Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f1c60-faf9-4a93-a0dc-d4b1ffc1b254",
   "metadata": {},
   "source": [
    "### Dataset splitting\n",
    "Split the dataset into training (70%) and test set (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c4817-5d7b-46e2-a8a0-a27516bf5026",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "use train_test_split(data, target, test_size, random)\n",
    "'''\n",
    "# Please fill your answer in '...'\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = dataset.drop('target', axis=1)\n",
    "y = dataset.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(..., ..., test_size=..., random_state=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f6f59-654d-4e87-a2ba-68ba836bbcba",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "Intuitively, random forest (RF) algorithm can be concerned as an extension of decision tree algorithm. RF consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction (see figure below).\n",
    "\n",
    "| ![](https://miro.medium.com/max/1000/1*VHDtVaDPNepRglIAv72BFg.jpeg) |\n",
    "|:--:|\n",
    "| <b>Visualization of a Random Forest Model Making a Prediction</b> |\n",
    "\n",
    "the fundamental concept behind RF is \"the wisdom of crowd\", which mean **A large number of relatively uncorrelated models (trees) operating as a committee will outperform any of the individual constituent models**. The reason for this wonderful effect is that the trees protect each other from their individual errors (as long as they don’t constantly all err in the same direction). Alternatively, in decision tree works separately and doesn't depend on each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7beb9a2-3c26-4bec-ad6d-8301f71ece42",
   "metadata": {},
   "source": [
    "#### Prerequisites for random forest\n",
    "- There needs to be some actual signal in our features so that models built using those features do better than random guessing.\n",
    "- The predictions (and therefore the errors) made by the individual trees need to have low correlations with each other.\n",
    "#### Ensure the model diverse\n",
    "In order to ensure the uncorrelation between trees and the behavior of each individual tree, we usually use two common methods:\n",
    "- Bagging (Bootstrap Aggregation) — Decisions trees are very sensitive to the data they are trained on — small changes to the training set can result in significantly different tree structures. For example, if our training data was [1, 2, 3, 4, 5, 6] then we might give one of our trees the following list [1, 2, 2, 3, 6, 6]. \n",
    "- Feature randomness - Each tree in a random forest can pick only from a random subset of features. This forces even more variation amongst the trees in the model.\n",
    "\n",
    "| ![](https://miro.medium.com/max/1000/1*EemYMyOADnT0lJWSXmTDdg.jpeg) |\n",
    "|:--:|\n",
    "| <b>Changing in data and features between trees in random forest</b> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d47de-c5bf-4206-8340-1190c752419c",
   "metadata": {},
   "source": [
    "## Build a random forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda5470-4edc-4ade-b051-1341fb3eddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Building a decision model with Scitkit Learn\n",
    "- set random_state to 42\n",
    "- set number of estimator (n_estimators) to 1000\n",
    "'''\n",
    "# Please fill your answer in '...'\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_clf = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa8d3a-fe75-4a10-b06d-557439b6ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(rf_clf, x_train, y_train, x_test, y_test, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b4dce6-319a-45b9-a318-c314543ae4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(rf_clf, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e380d-0ed0-4c9b-86a7-76dae0e5758c",
   "metadata": {},
   "source": [
    "## Improve model with hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970c3af-34fd-4237-bb0c-061cc378a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implement some different hyperparameters to test their efficacy on new random forest model: \n",
    "n_estimators, max_features, max_depth, min_samples_split, min_samples_leaf, bootstrap\n",
    "'''\n",
    "# Please fill your answer in '...'\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "params_grid = {...}\n",
    "\n",
    "# rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_cv = GridSearchCV(..., ..., scoring=\"accuracy\", cv=3, verbose=2, n_jobs=-1).fit(x_train, y_train)\n",
    "best_params = rf_cv.best_params_\n",
    "print(f'Best_params: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31643d4e-a778-46a9-9345-7da98e1a2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_tuning = RandomForestClassifier(**best_params).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4003c09b-af3f-453d-a047-4e3f18ebcfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(rf_clf_tuning, x_train, y_train, x_test, y_test, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d05696a-d420-4ebb-a826-3c8692f5cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(rf_clf_tuning, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd187ac2-8f89-4928-bfaf-6983a4201bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Summarize the accuracy score of random forest algorithm with and without hyperparameters.\n",
    "'''\n",
    "# Please fill your answer in '...'\n",
    "rf_clf_train = accuracy_score(y_train, rf_clf.predict(x_train)) * 100\n",
    "rf_clf_test = accuracy_score(y_test, rf_clf.predict(x_test)) * 100\n",
    "rf_clf_tuning_train = ...\n",
    "rf_clf_tuning_test = ...\n",
    "\n",
    "result = pd.DataFrame(columns=['Model', 'Non-tuning train accuracy %', 'Tuning train accuracy %', 'Non-tuning test accuracy %', 'Tuning test accuracy %'])\n",
    "dt_result = pd.DataFrame(data=[['Random Forest', ..., ..., ..., ...]],\n",
    "                        columns=['Model', 'Non-tuning train accuracy %', 'Tuning train accuracy %', 'Non-tuning test accuracy %', 'Tuning test accuracy %'])\n",
    "result = result.append(dt_result, ignore_index=True)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
